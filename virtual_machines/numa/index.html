<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://kubevirt.io/user-guide/virtual_machines/numa/" />
      <link rel="shortcut icon" href="../../assets/favicon.ico" />
    <title>NUMA - KubeVirt User-Guide</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "NUMA";
        var mkdocs_page_input_path = "virtual_machines/numa.md";
        var mkdocs_page_url = "/user-guide/virtual_machines/numa/";
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> KubeVirt User-Guide
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Welcome</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../architecture/">Architecture</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../quickstarts/">Quickstarts</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../release_notes/">KubeVirt release notes</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Operations</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/updating_and_deletion/">Updating and deletion</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/basic_use/">Basic use</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/customize_components/">Customize components</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/api_validation/">API Validation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/debug/">Debug</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/virtctl_client_tool/">virtctl Client Tool</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/live_migration/">Live Migration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/hotplug_volumes/">Hotplug Volumes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/client_passthrough/">Client Passthrough</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/snapshot_restore_api/">Snapshot Restore API</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/hugepages/">Hugepages support</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/component_monitoring/">Component monitoring</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/authorization/">Authorization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/annotations_and_labels/">Annotations and labels</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/node_assignment/">Node assignment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/node_maintenance/">Node maintenance</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/node_overcommit/">Node overcommit</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/unresponsive_nodes/">Unresponsive nodes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/containerized_data_importer/">Containerized Data Importer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/activating_feature_gates/">Activating feature gates</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/export_api/">Export API</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/clone_api/">Clone API</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/memory_dump/">Virtual machine memory dump</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/mediated_devices_configuration/">Mediated devices and virtual GPUs</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../operations/migration_policies/">Migration Policies</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Virtual machines</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../virtual_machine_instances/">Virtual Machines Instances</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../lifecycle/">Lifecycle</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../run_strategies/">Run Strategies</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../instancetypes/">Instancetypes and preferences</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../presets/">Presets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../virtual_hardware/">Virtual hardware</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dedicated_cpu_resources/">Dedicated CPU resources</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">NUMA</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#preconditions">Preconditions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#guestmappingpassthrough">GuestMappingPassthrough</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#running-real-time-workloads">Running real-time workloads</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#preconditions_1">Preconditions</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#nodes-capable-of-running-real-time-workloads">Nodes capable of running real-time workloads</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#configuring-a-vm-manifest">Configuring a VM Manifest</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#how-to-dedicate-vcpus-for-real-time-only">How to dedicate VCPUS for real-time only</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../disks_and_volumes/">Disks and Volumes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../interfaces_and_networks/">Interfaces and Networks</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../istio_service_mesh/">Istio service mesh</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../networkpolicy/">NetworkPolicy</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../host-devices/">Host Devices Assignment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../windows_virtio_drivers/">Windows virtio drivers</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../guest_operating_system_information/">Guest Operating System Information</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../guest_agent_information/">Guest Agent information</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../liveness_and_readiness_probes/">Liveness and Readiness Probes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../accessing_virtual_machines/">Accessing Virtual Machines</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../startup_scripts/">Startup Scripts</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../service_objects/">Service objects</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../templates/">Templates</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../tekton_tasks/">KubeVirt Tekton</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../replicaset/">VirtualMachineInstanceReplicaSet</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dns/">DNS records</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../boot_from_external_source/">Booting From External Source</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../confidential_computing/">Confidential computing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../vsock/">VSOCK</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../web_console/">Web Console</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Appendix</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../appendix/contributing/">Contributing</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">KubeVirt User-Guide</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Virtual machines &raquo;</li>
      <li>NUMA</li>
    <li class="wy-breadcrumbs-aside">
        <a href="https://github.com/kubevirt/user-guide/edit/main/docs/virtual_machines/numa.md"
          class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="numa">NUMA<a class="headerlink" href="#numa" title="Permanent link">&para;</a></h1>
<p><strong>FEATURE STATE:</strong> KubeVirt v0.43</p>
<p>NUMA support in KubeVirt is at this stage limited to a small set of special
use-cases and will improve over time together with improvements made to
Kubernetes.</p>
<p>In general, the goal is to map the host NUMA topology as efficiently as possible
to the Virtual Machine topology to improve the performance.</p>
<p>The following NUMA mapping strategies can be used:</p>
<ul>
<li><a href="#guestmappingpassthrough"><strong>GuestMappingPassthrough</strong></a></li>
</ul>
<h2 id="preconditions">Preconditions<a class="headerlink" href="#preconditions" title="Permanent link">&para;</a></h2>
<p>In order to use current NUMA support, the following preconditions must be met:</p>
<ul>
<li><a href="../dedicated_cpu_resources/">Dedicated CPU Resources</a> must be configured.</li>
<li><a href="../virtual_hardware/#hugepages">Hugepages</a> need to be allocatable on target
  nodes.</li>
<li>The <code>NUMA</code>
  <a href="../../operations/activating_feature_gates/#how-to-activate-a-feature-gate">feature gate</a>
  must be enabled.</li>
</ul>
<h2 id="guestmappingpassthrough">GuestMappingPassthrough<a class="headerlink" href="#guestmappingpassthrough" title="Permanent link">&para;</a></h2>
<p>GuestMappingPassthrough will pass through the node numa topology to the guest.
The topology is based on the dedicated CPUs which the VMI got assigned from the
kubelet via the CPU Manager. It can be requested by
setting <code>spec.domain.cpu.guestMappingPassthrough</code> on the VMI.</p>
<p>Since KubeVirt does not know upfront which exclusive CPUs the VMI will get from
the kubelet, there are some limitations:</p>
<ul>
<li>Guests may see different NUMA topologies when being rescheduled.</li>
<li>The resulting NUMA topology may be asymmetrical.</li>
<li>The VMI may fail to start on the node if not enough hugepages are available on
  the assigned NUMA nodes.</li>
</ul>
<p>While this NUMA modelling strategy has its limitations, aligning the guest's
NUMA architecture with the node's can be critical for high-performance
applications.</p>
<p>An example VMI may look like this:</p>
<pre><code class="language-yaml">apiVersion: kubevirt.io/v1
kind: VirtualMachineInstance
metadata:
  name: numavm
spec:
  domain:
    cpu:
      cores: 4
      dedicatedCpuPlacement: true
      numa:
        guestMappingPassthrough: { }
    devices:
      disks:
        - disk:
            bus: virtio
          name: containerdisk
        - disk:
            bus: virtio
          name: cloudinitdisk
    resources:
      requests:
        memory: 64Mi
    memory:
      hugepages:
        pageSize: 2Mi
  volumes:
    - containerDisk:
        image: quay.io/kubevirt/cirros-container-disk-demo
      name: containerdisk
    - cloudInitNoCloud:
        userData: |
          #!/bin/sh
          echo 'printed from cloud-init userdata'
      name: cloudinitdisk
</code></pre>
<h2 id="running-real-time-workloads">Running real-time workloads<a class="headerlink" href="#running-real-time-workloads" title="Permanent link">&para;</a></h2>
<h3 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h3>
<p>It is possible to deploy Virtual Machines that run a real-time kernel and make use of <a href="https://www.libvirt.org/kbase/kvm-realtime.html">libvirtd's guest cpu and memory optimizations</a> that improve the overall latency. These changes leverage mostly on already available settings in KubeVirt, as we will see shortly, but the VMI manifest now exposes two new settings that instruct KubeVirt to configure the generated libvirt XML with the recommended tuning settings for running real-time workloads.</p>
<p>To make use of the optimized settings, two new settings have been added to the VMI schema:</p>
<ul>
<li>
<p><code>spec.domain.cpu.realtime</code>: When defined, it instructs KubeVirt to configure the linux scheduler for the VCPUS to run processes in FIFO scheduling policy (SCHED_FIFO) with priority 1. This setting guarantees that all processes running in the host will be executed with real-time priority.</p>
</li>
<li>
<p><code>spec.domain.cpu.realtime.mask</code>: It defines which VCPUs assigned to the VM are used for real-time. If not defined, libvirt will define all VCPUS assigned to run processes in FIFO scheduling and in the highest priority (1).</p>
</li>
</ul>
<h3 id="preconditions_1">Preconditions<a class="headerlink" href="#preconditions_1" title="Permanent link">&para;</a></h3>
<p>A prerequisite to running real-time workloads include locking resources in the cluster to allow the real-time VM exclusive usage. This translates into nodes, or node, that have been configured with a <a href="https://github.com/kubevirt/user-guide/blob/main/docs/virtual_machines/dedicated_cpu_resources.md">dedicated set of CPUs</a> and also provides support for <a href="https://github.com/kubevirt/user-guide/blob/main/docs/virtual_machines/numa.md">NUMA</a> with a free number of hugepages of 2Mi or 1Gi size (depending on the configuration in the VMI). Additionally, the node must be configured to allow the scheduler to run processes with real-time policy.</p>
<h3 id="nodes-capable-of-running-real-time-workloads">Nodes capable of running real-time workloads<a class="headerlink" href="#nodes-capable-of-running-real-time-workloads" title="Permanent link">&para;</a></h3>
<p>When the KubeVirt pods are deployed in a node, it will check if it is capable of running processes in real-time scheduling policy and label the node as real-time capable (kubevirt.io/realtime). If, on the other hand, the node is not able to deliver such capability, the label is not applied. To check which nodes are able to host real-time VM workloads run this command:</p>
<pre><code class="language-bash">$&gt;kubectl get nodes -l kubevirt.io/realtime
NAME         STATUS   ROLES              AGE    VERSION
worker-0-0   Ready    worker             12d    v1.20.0+df9c838
</code></pre>
<p>Internally, the KubeVirt pod running in each node checks if the kernel setting <code>kernel.sched_rt_runtime_us</code> equals to -1, which grants processes to run in real-time scheduling policy for an unlimited amount of time.</p>
<h3 id="configuring-a-vm-manifest">Configuring a VM Manifest<a class="headerlink" href="#configuring-a-vm-manifest" title="Permanent link">&para;</a></h3>
<p>Here is an example of a VM manifest that runs a custom fedora container disk configured to run with a real-time kernel. The settings have been configured for optimal efficiency.</p>
<pre><code class="language-yaml">---
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  labels:
    kubevirt.io/vm: fedora-realtime
  name: fedora-realtime
spec:
  running: true
  template:
    metadata:
      labels:
        kubevirt.io/vm: fedora-realtime
    spec:
      domain:
        devices:
          autoattachSerialConsole: true
          autoattachMemBalloon: false
          autoattachGraphicsDevice: false
          disks:
          - disk:
              bus: virtio
            name: containerdisk 
          - disk:
              bus: virtio
            name: cloudinitdisk
        machine:
          type: &quot;&quot;
        resources:
          requests:
            memory: 1Gi
            cpu: 2
          limits:
            memory: 1Gi
            cpu: 2
        cpu:
          model: host-passthrough
          dedicatedCpuPlacement: true
          isolateEmulatorThread: true
          ioThreadsPolicy: auto
          features:
            - name: tsc-deadline
              policy: require
          numa:
            guestMappingPassthrough: {}
          realtime: {}
        memory:
          hugepages:
            pageSize: 1Gi
      terminationGracePeriodSeconds: 0
      volumes:
      - containerDisk:
          image: quay.io/kubevirt/fedora-realtime-container-disk:v20211008-22109a3
        name: containerdisk
      - cloudInitNoCloud:
          userData: |-
            #cloud-config
            password: fedora
            chpasswd: { expire: False }
            bootcmd:
              - tuned-adm profile realtime
        name: cloudinitdisk
</code></pre>
<p>Breaking down the tuned sections, we have the following configuration:</p>
<p><a href="https://libvirt.org/kbase/kvm-realtime.html#device-configuration">Devices</a>: 
- Disable the guest's memory balloon capability
- Avoid attaching a graphics device, to reduce the number of interrupts to the kernel.</p>
<pre><code class="language-yaml">    spec:
      domain:
        devices:
          autoattachSerialConsole: true
          autoattachMemBalloon: false
          autoattachGraphicsDevice: false
</code></pre>
<p><a href="https://libvirt.org/kbase/kvm-realtime.html#cpu-configuration">CPU</a>:
- model: <code>host-passthrough</code> to allow the guest to see host CPU without masking any capability.
- dedicated CPU Placement: The VM needs to have dedicated CPUs assigned to it. The Kubernetes CPU Manager takes care of this aspect.
- isolatedEmulatorThread: to request an additional CPU to run the emulator on it, thus avoid using CPU cycles from the workload CPUs.
- ioThreadsPolicy: Set to auto to let the dedicated IO thread to run in the same CPU as the emulator thread.
- NUMA: defining <code>guestMappingPassthrough</code> enables NUMA support for this VM.
- realtime: instructs the virt-handler to configure this VM for real-time workloads, such as configuring the VCPUS to use FIFO scheduler policy and set priority to 1.
cpu:</p>
<pre><code class="language-yaml">        cpu:
          model: host-passthrough
          dedicatedCpuPlacement: true
          isolateEmulatorThread: true
          ioThreadsPolicy: auto
          features:
            - name: tsc-deadline
              policy: require
          numa:
            guestMappingPassthrough: {}
          realtime: {}
</code></pre>
<p><a href="https://libvirt.org/kbase/kvm-realtime.html#memory-configuration">Memory</a>
- pageSize: allocate the pod's memory in hugepages of the given size, in this case of 1Gi.</p>
<pre><code class="language-yaml">        memory:
          hugepages:
            pageSize: 1Gi
</code></pre>
<h3 id="how-to-dedicate-vcpus-for-real-time-only">How to dedicate VCPUS for real-time only<a class="headerlink" href="#how-to-dedicate-vcpus-for-real-time-only" title="Permanent link">&para;</a></h3>
<p>It is possible to pass a regular expression of the VCPUs to isolate to use real-time scheduling policy, by using the <code>realtime.mask</code> setting.</p>
<pre><code class="language-yaml">        cpu:
          numa:
            guestMappingPassthrough: {}
          realtime:
            mask: &quot;0&quot;
</code></pre>
<p>When applied this configuration, KubeVirt will only set the first VCPU for real-time scheduler policy, leaving the remaining VCPUS to use the default scheduler policy. Other examples of valid masks are:
- <code>0-3</code>: Use cores 0 to 3 for real-time scheduling, assuming that the VM has requested at least 3 cores.
- <code>0-3,^1</code>: Use cores 0, 2 and 3 for real-time scheduling only, assuming that the VM has requested at least 3 cores.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../dedicated_cpu_resources/" class="btn btn-neutral float-left" title="Dedicated CPU resources"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../disks_and_volumes/" class="btn btn-neutral float-right" title="Disks and Volumes">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/kubevirt/user-guide/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../dedicated_cpu_resources/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../disks_and_volumes/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(false);
        };
    </script>

</body>
</html>
